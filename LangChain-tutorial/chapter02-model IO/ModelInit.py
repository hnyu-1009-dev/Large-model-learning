from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import os
import dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv(
    # åœ¨å·¥ç¨‹æ ¹ç›®å½•åªä¿ç•™ä¸€ä¸ª .envï¼Œæ‰€æœ‰æ¨¡å—éƒ½å¼•ç”¨å®ƒã€‚è¿™æ˜¯æœ€ä¸å®¹æ˜“å‡ºé”™çš„æ–¹å¼ã€‚
    override=True,  # å¦‚æœåŠ è½½.envæ–‡ä»¶å‡ºç°äº†åŒåç¯å¢ƒå˜è„¸ï¼Œä¼šè¿›è¡Œè¦†ç›–
    # dotenv_path=".env",  # å¯ä»¥åªå½“éœ€è¦åŠ è½½çš„è·¯å¾„
)

"""
    # 1.LangChain çš„åº•å±‚ä»£ç é»˜è®¤ä¼šå¯»æ‰¾åä¸º "OPENAI_API_KEY" å’Œ "OPENAI_API_BASE" çš„å˜é‡
    #   è¿™é‡Œé€šè¿‡ os.environ å°†ä½ è‡ªå®šä¹‰çš„å˜é‡åï¼ˆå¦‚ OPENAI_API_KEY1ï¼‰æ˜ å°„åˆ°æ ‡å‡†å˜é‡åä¸Š
    os.environ["SILICON_FLOW_API_KEY"] = os.getenv("SILICON_FLOW_API_KEY")
    os.environ["SILICON_FLOW_BASE_URL"] = os.getenv("SILICON_FLOW_BASE_URL")

    # å› æ­¤å°†å˜é‡æ˜ å°„å¥½åï¼Œåˆå§‹åŒ–æ¨¡å‹æ—¶ï¼Œå°±å¯ä»¥ä¸ç”¨æŒ‡å®šAPIå‚æ•°äº†
    # 2. åˆå§‹åŒ–æ¨¡å‹ï¼šæ­¤æ—¶ LangChain ä¼šè‡ªåŠ¨æ‰¾åˆ°ä¸Šé¢çš„ç¯å¢ƒå˜é‡ï¼Œæ— éœ€ä¼ å‚
    chat_model = ChatOpenAI(
        model="Qwen/Qwen2.5-7B-Instruct",
        temperature=0.7
    )
"""

# 1. å½±å“èŒƒå›´ï¼šä»…é™å½“å‰è¿›ç¨‹ï¼ˆåŠå…¶å­è¿›ç¨‹ï¼‰
#     å½“å‰æ–‡ä»¶ï¼šå½“ä½ è¿è¡Œè¿™ä¸ª .py æ–‡ä»¶æ—¶ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªæ“ä½œç³»ç»Ÿè¿›ç¨‹ã€‚è¿™ä¸¤è¡Œä»£ç åœ¨å†…å­˜ä¸­ä¿®æ”¹äº†è¯¥è¿›ç¨‹çš„ç¯å¢ƒå˜é‡å­—å…¸ã€‚
#
#     æ•´ä¸ªå·¥ç¨‹ï¼šå¦‚æœä½ çš„å·¥ç¨‹ä¸­æœ‰å…¶ä»– .py æ–‡ä»¶ï¼Œåªè¦å®ƒä»¬ä¸æ˜¯ç”±å½“å‰è¿™ä¸ªæ–‡ä»¶å¯åŠ¨çš„ï¼ˆæ¯”å¦‚ä½ å•ç‹¬å¼€äº†å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œå¦ä¸€ä¸ªæ–‡ä»¶ï¼‰ï¼Œ
#     é‚£ä¹ˆå®ƒä»¬æ— æ³•è¯»å–åˆ°è¿™é‡Œçš„æ˜ å°„ã€‚
#
#     å­è¿›ç¨‹ï¼šå¦‚æœä½ åœ¨è¿™ä¸ªè„šæœ¬ä¸­è°ƒç”¨äº†å…¶ä»–å­ç¨‹åºï¼ˆæ¯”å¦‚é€šè¿‡ os.system è¿è¡Œè„šæœ¬ï¼‰ï¼Œé‚£ä¹ˆè¿™äº›å­ç¨‹åºé€šå¸¸ä¼šç»§æ‰¿è¿™ä¸ªæ˜ å°„ã€‚
#
# 2. ç”Ÿå‘½å‘¨æœŸï¼šéšè¿è¡Œç»“æŸè€Œæ¶ˆå¤±
#     å†…å­˜å­˜å‚¨ï¼šos.environ çš„ä¿®æ”¹æ˜¯å­˜å‚¨åœ¨å†…å­˜ä¸­çš„ã€‚
#
#     æŒä¹…æ€§ï¼šå®ƒä¸ä¼šä¿®æ”¹ä½ ç¡¬ç›˜ä¸Šçš„ .env æ–‡ä»¶ï¼Œä¹Ÿä¸ä¼šä¿®æ”¹æ“ä½œç³»ç»Ÿçš„å…¨å±€è®¾ç½®ã€‚ä¸€æ—¦ä½ ç‚¹å‡» VS Code çš„åœæ­¢æŒ‰é’®æˆ–è€…ç¨‹åºè¿è¡Œç»“æŸï¼Œ
#     è¿™ä¸ªæ˜ å°„å°±ä¼šç«‹å³è¢«é”€æ¯ã€‚ä¸‹æ¬¡è¿è¡Œï¼Œå¿…é¡»é‡æ–°æ‰§è¡Œè¿™ä¸¤è¡Œä»£ç æ‰èƒ½ç”Ÿæ•ˆã€‚


# åˆå§‹åŒ–æ¨¡å‹
# æç¤ºï¼šç¡…åŸºæµåŠ¨å¹³å°æ¨¡å‹é€šå¸¸å»ºè®®å¼€å¯ streaming=True æ¥è·å¾—æ›´å¥½çš„äº¤äº’ä½“éªŒ
chat_model = ChatOpenAI(
    api_key=os.getenv("SILICON_FLOW_API_KEY"),
    base_url=os.getenv("SILICON_FLOW_BASE_URL"),
    model="Qwen/Qwen2.5-7B-Instruct",  # ç¡®ä¿æ¨¡å‹åç§°å‡†ç¡®
    temperature=0.7,
)

# --- æ ¸å¿ƒï¼šç†è§£æ¶ˆæ¯åˆ—è¡¨ (Messages List) ---
# æ¶ˆæ¯åˆ—è¡¨æ˜¯ä¸€ä¸ªâ€œå†å²è®°å½•å †æ ˆâ€ï¼Œæ¨¡å‹é€šè¿‡é˜…è¯»è¿™ä¸ªåˆ—è¡¨æ¥è·å–ä¸Šä¸‹æ–‡
messages = [
    # 1. SystemMessage (ç³»ç»Ÿæ¶ˆæ¯)
    # ä½œç”¨ï¼šè®¾å®šâ€œäººè®¾â€å’Œâ€œè§„åˆ™â€ã€‚å®ƒæ˜¯ AI çš„åº•å±‚é€»è¾‘ï¼Œä¸ä¼šè½»æ˜“æ”¹å˜ã€‚
    SystemMessage(
        content="ä½ æ˜¯ä¸€ä½ç²¾é€šå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆçš„åˆ›ä½œåŠ©æ‰‹ï¼Œè¯´è¯å¹½é»˜ï¼Œå–œæ¬¢ç”¨ Emojiã€‚"
    ),
    # 2. HumanMessage (ç”¨æˆ·æ¶ˆæ¯)
    # ä½œç”¨ï¼šæ¨¡æ‹Ÿä½ å¯¹ AI è¯´çš„è¯ã€‚
    HumanMessage(content="ä½ å¥½ï¼Œæˆ‘æƒ³å†™ä¸€ä¸ªå…³äºâ€˜AIå†™å°è¯´â€™çš„æ¨æ–‡æ ‡é¢˜ã€‚"),
    # 3. AIMessage (åŠ©æ‰‹æ¶ˆæ¯ - æ¨¡æ‹Ÿè®°å¿†)
    # ä½œç”¨ï¼šä»£è¡¨ AI ä¹‹å‰è¯´çš„è¯ã€‚é€šè¿‡æ‰‹åŠ¨æ·»åŠ  AIMessageï¼Œä½ å¯ä»¥â€œä¼ªé€ â€è®°å¿†ï¼Œ
    # ä»è€Œè®©æ¨¡å‹åœ¨æ¥ä¸‹æ¥çš„å›å¤ä¸­ä¿æŒé€»è¾‘ä¸€è‡´ã€‚
    AIMessage(
        content="æ²¡é—®é¢˜ï¼æˆ‘ä»¬å¯ä»¥ä»â€˜å‰¯ä¸šèµšé’±â€™æˆ–è€…â€˜ç§‘æŠ€é»‘å®¢â€™ä¸¤ä¸ªè§’åº¦åˆ‡å…¥ã€‚ä½ æ›´å€¾å‘å“ªä¸ªï¼Ÿ"
    ),
    # 4. å†æ¬¡æé—®ï¼ˆæ¨¡æ‹Ÿå¤šè½®å¯¹è¯ï¼‰
    HumanMessage(content="é€‰ç§‘æŠ€é»‘å®¢è§’åº¦ï¼Œè¦é…·ä¸€ç‚¹ã€‚"),
]

# è°ƒç”¨æ¨¡å‹
# æ¨¡å‹ä¼šé˜…è¯»ä¸Šé¢æ‰€æœ‰çš„æ¶ˆæ¯ï¼Œæ„è¯†åˆ°ç°åœ¨æ˜¯å¯¹è¯çš„â€œç¬¬å››å›åˆâ€
response = chat_model.invoke(messages)

# --- å¤„ç†å“åº”æ•°æ® ---
print("--- åŸå§‹å“åº”å¯¹è±¡ ---")
print(response)

print("\n--- çº¯æ–‡æœ¬å›å¤ ---")
print(response.content)

print("\n--- Token æ¶ˆè€—è¯¦æƒ… ---")
# è®°å½•æˆæœ¬çš„å…³é”®æ•°æ®
usage = response.response_metadata.get("token_usage", {})
print("response.response_metadata", response.response_metadata)
print("usage", usage)
print(f"è¾“å…¥: {usage.get('prompt_tokens')} | è¾“å‡º: {usage.get('completion_tokens')}")

# ====================================================================== #
# 1. åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨ï¼Œè®¾å®šç³»ç»Ÿäººè®¾
# è¿™é‡Œçš„ history[0] æ°¸è¿œæ˜¯ä½ çš„â€œå°è¯´å®¶â€èº«ä»½
history = [SystemMessage(content="ä½ æ˜¯ä¸€ä½ç²¾é€šæƒ…èŠ‚è®¾è®¡çš„ç„å¹»å°è¯´å®¶ã€‚")]

print("--- ğŸ¤– å°è¯´åˆ›ä½œåŠ©æ‰‹å·²å°±ç»ª (è¾“å…¥ 'exit' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯) ---")

while True:
    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = input("\nğŸ‘¤ ä½ çš„æŒ‡ä»¤: ")

    # --- æ ¸å¿ƒæ”¹è¿›ï¼šæ·»åŠ é€€å‡ºé€»è¾‘ ---
    # .strip() å»é™¤ç©ºæ ¼ï¼Œ.lower() ç»Ÿä¸€è½¬ä¸ºå°å†™ï¼Œå¢åŠ å®¹é”™ç‡
    if user_input.strip().lower() in ["exit", "quit", "é€€å‡º", "stop"]:
        print("ğŸš€ æ­£åœ¨ä¿å­˜ä¼šè¯å¹¶é€€å‡º... åˆ›ä½œè¾›è‹¦äº†ï¼")
        break

    # å°†æœ‰æ•ˆçš„ç”¨æˆ·è¾“å…¥å­˜å…¥å†å²
    history.append(HumanMessage(content=user_input))

    # --- æ ¸å¿ƒæ”¹è¿›ï¼šäººè®¾ä¿æŠ¤æœºåˆ¶ ---
    # å¦‚æœç›´æ¥ä½¿ç”¨ history[-10:]ï¼Œå½“å¯¹è¯å¾ˆé•¿æ—¶ï¼Œhistory[0] (SystemMessage) ä¼šè¢«ä¸¢å¼ƒ
    # å¯¼è‡´ AI å¿˜è®°è‡ªå·±æ˜¯â€œå°è¯´å®¶â€ã€‚
    # ä¼˜åŒ–æ–¹æ¡ˆï¼šå§‹ç»ˆä¿ç•™ history[0]ï¼Œå†åŠ ä¸Šæœ€è¿‘çš„ 10 æ¡å¯¹è¯
    if len(history) > 10:
        # æ‹¼æ¥ï¼š[ç³»ç»Ÿæ¶ˆæ¯] + [æœ€è¿‘çš„10æ¡æ¶ˆæ¯]
        current_context = [history[0]] + history[-10:]
    else:
        current_context = history

    # è°ƒç”¨æ¨¡å‹
    res = chat_model.invoke(current_context)

    # æ‰“å° AI å›å¤å¹¶å­˜å…¥å†å²
    print(f"\nâœï¸  AI: {res.content}")
    history.append(res)
