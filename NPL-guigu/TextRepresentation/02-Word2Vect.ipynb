{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55d74bd",
   "metadata": {},
   "source": [
    "# 第一节 加载公开词向量"
   ]
  },
  {
   "cell_type": "code",
   "id": "24c82072efc44ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:13:41.066752Z",
     "start_time": "2026-01-06T03:12:49.090605Z"
    }
   },
   "source": [
    "import jieba\n",
    "# 可以把解压后的文件导入，也可以把压缩包导入，支持自动解压\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = '../../Data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5.bz2'\n",
    "model = KeyedVectors.load_word2vec_format(model_path)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgensim\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KeyedVectors\n\u001B[32m      5\u001B[39m model_path = \u001B[33m'\u001B[39m\u001B[33m../../Data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5.bz2\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m model = \u001B[43mKeyedVectors\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_word2vec_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1721\u001B[39m, in \u001B[36mKeyedVectors.load_word2vec_format\u001B[39m\u001B[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[39m\n\u001B[32m   1674\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m   1675\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_word2vec_format\u001B[39m(\n\u001B[32m   1676\u001B[39m         \u001B[38;5;28mcls\u001B[39m, fname, fvocab=\u001B[38;5;28;01mNone\u001B[39;00m, binary=\u001B[38;5;28;01mFalse\u001B[39;00m, encoding=\u001B[33m'\u001B[39m\u001B[33mutf8\u001B[39m\u001B[33m'\u001B[39m, unicode_errors=\u001B[33m'\u001B[39m\u001B[33mstrict\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   1677\u001B[39m         limit=\u001B[38;5;28;01mNone\u001B[39;00m, datatype=REAL, no_header=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   1678\u001B[39m     ):\n\u001B[32m   1679\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001B[39;00m\n\u001B[32m   1680\u001B[39m \n\u001B[32m   1681\u001B[39m \u001B[33;03m    Warnings\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1719\u001B[39m \n\u001B[32m   1720\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1721\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_word2vec_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1722\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfvocab\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbinary\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbinary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43municode_errors\u001B[49m\u001B[43m=\u001B[49m\u001B[43municode_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1723\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatatype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdatatype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_header\u001B[49m\u001B[43m=\u001B[49m\u001B[43mno_header\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1724\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2071\u001B[39m, in \u001B[36m_load_word2vec_format\u001B[39m\u001B[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[39m\n\u001B[32m   2067\u001B[39m         _word2vec_read_binary(\n\u001B[32m   2068\u001B[39m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001B[32m   2069\u001B[39m         )\n\u001B[32m   2070\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2071\u001B[39m         \u001B[43m_word2vec_read_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcounts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvector_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatatype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43municode_errors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2072\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kv.vectors.shape[\u001B[32m0\u001B[39m] != \u001B[38;5;28mlen\u001B[39m(kv):\n\u001B[32m   2073\u001B[39m     logger.info(\n\u001B[32m   2074\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mduplicate words detected, shrinking matrix size from \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[33m to \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m   2075\u001B[39m         kv.vectors.shape[\u001B[32m0\u001B[39m], \u001B[38;5;28mlen\u001B[39m(kv),\n\u001B[32m   2076\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1973\u001B[39m, in \u001B[36m_word2vec_read_text\u001B[39m\u001B[34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001B[39m\n\u001B[32m   1971\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_word2vec_read_text\u001B[39m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding):\n\u001B[32m   1972\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m line_no \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(vocab_size):\n\u001B[32m-> \u001B[39m\u001B[32m1973\u001B[39m         line = fin.readline()\n\u001B[32m   1974\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m line == \u001B[33mb\u001B[39m\u001B[33m'\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m   1975\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33munexpected end of input; is count incorrect or file otherwise damaged?\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\bz2.py:184\u001B[39m, in \u001B[36mBZ2File.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m    179\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Read bytes into b.\u001B[39;00m\n\u001B[32m    180\u001B[39m \n\u001B[32m    181\u001B[39m \u001B[33;03mReturns the number of bytes read (0 for EOF).\u001B[39;00m\n\u001B[32m    182\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    183\u001B[39m \u001B[38;5;28mself\u001B[39m._check_can_read()\n\u001B[32m--> \u001B[39m\u001B[32m184\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._buffer.readinto(b)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\_compression.py:68\u001B[39m, in \u001B[36mDecompressReader.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[32m     67\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view.cast(\u001B[33m\"\u001B[39m\u001B[33mB\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbyte_view\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     69\u001B[39m         byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] = data\n\u001B[32m     70\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\_compression.py:103\u001B[39m, in \u001B[36mDecompressReader.read\u001B[39m\u001B[34m(self, size)\u001B[39m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    102\u001B[39m         rawblock = \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m     data = \u001B[38;5;28mself\u001B[39m._decompressor.decompress(rawblock, size)\n\u001B[32m    104\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[32m    105\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40909aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:13:41.121762200Z",
     "start_time": "2026-01-05T08:10:33.847250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[ 0.567997  0.158654  0.038625  0.249258 -0.196332  0.213017 -0.136925\n",
      "  0.232799  0.144968 -0.09523   0.425262 -0.092607  0.694388  0.025083\n",
      " -0.183769 -0.201074  0.223489 -0.26399  -0.072578  0.147112  0.353904\n",
      " -0.166529 -0.194957 -0.026473 -0.113792  0.185063  0.357284  0.542023\n",
      "  0.231774  0.57543  -0.405007 -0.163268  0.269997 -0.120403  0.414961\n",
      " -0.066652 -0.421365 -0.015576 -0.012792 -0.184059 -0.110147 -0.007924\n",
      "  0.036816 -0.154306  0.230923 -0.083318 -0.516196 -0.538834  0.117642\n",
      " -0.210153 -0.124584 -0.212592 -0.05337   0.329235 -0.076741 -0.467959\n",
      " -0.294227 -0.00829  -0.243343  0.056438  0.028466  0.117502  0.62926\n",
      " -0.650896 -0.295166 -0.244159  0.421573  0.115636  0.212001  0.418772\n",
      " -0.40834  -0.265115 -0.042153  0.055105 -0.323379 -0.493779  0.02188\n",
      "  0.180165 -0.222311  0.024993 -0.417476 -0.060329  0.050551 -0.329032\n",
      " -0.675789 -0.372138 -0.246428  0.265466 -0.1353    0.188153 -0.054184\n",
      " -0.288865  0.596618 -0.058765 -0.349856  0.044062 -0.042164 -0.238806\n",
      "  0.337673 -0.231217 -0.310406  0.344858 -0.18085   0.422033  0.134592\n",
      "  0.04248   0.150471  0.46548   0.17257   0.213683 -0.246271  0.036252\n",
      " -0.559789 -0.163441 -0.220405 -0.208212 -0.106506  0.257365  0.219642\n",
      "  0.224648 -0.341812  0.551088  0.164098 -0.598947 -0.204246 -0.08475\n",
      " -0.224978  0.191686 -0.005582  0.083691 -0.644049  0.233565 -0.202639\n",
      "  0.403046 -0.169079 -0.223802 -0.109907 -0.123438 -0.03871  -0.754283\n",
      "  0.207664  0.057334  0.193155 -0.125986 -0.279145  0.255931  0.114884\n",
      "  0.108222 -0.149282 -0.26001  -0.539277  0.641472  0.029692 -0.334083\n",
      " -0.153011  0.210991  0.121913 -0.236693 -0.083735 -0.125289 -0.156986\n",
      "  0.092689 -0.109352  0.164506 -0.73591   0.128567  0.033405  0.270931\n",
      " -0.025962 -0.17141  -0.154056 -0.363888 -0.031858 -0.045183  0.339752\n",
      " -0.141307 -0.08037   0.460998 -0.357557  0.232051  0.290994  0.075107\n",
      " -0.646532 -0.022673  0.615375  0.171604 -0.480757  0.028607 -0.8949\n",
      "  0.213358 -0.191007 -0.007696  0.4284   -0.351353 -0.051624  0.048741\n",
      " -0.103956 -0.150913  0.012045  0.228132 -0.057625 -0.20482   0.012905\n",
      "  0.163923  0.320284 -0.241404 -0.200767  0.62779  -0.223826  0.425773\n",
      "  0.141232  0.093461  0.017982 -0.009254  0.436351  0.435626  0.792772\n",
      "  0.221    -0.007561 -0.08271  -0.413692 -0.086796 -0.423203  0.117092\n",
      "  0.260358  0.106988 -0.025311 -0.32874  -0.359797  0.067947 -0.028627\n",
      " -0.249087 -0.208021 -0.591613 -0.43223   0.194254 -0.400918  0.136515\n",
      " -0.681539  0.030137 -0.010532  0.68882  -0.080344  0.023515 -0.18774\n",
      " -0.428342 -0.116475  0.280905 -0.866591 -0.215359  0.008741 -0.829324\n",
      " -0.068058 -0.174436 -0.108931  0.420348 -0.449736  0.021749  0.27217\n",
      " -0.676005  0.418002  0.393078 -0.140047  0.238438  0.188567 -0.068242\n",
      "  0.189004  0.277244 -0.280798  0.270372 -0.127194  0.198697 -0.069034\n",
      " -0.508528 -0.215542  0.101144  0.425623 -0.152888 -0.216456  0.431299\n",
      " -0.237024 -0.273135 -0.090933 -0.395044  0.531943 -0.24069  -0.393809\n",
      " -0.093308 -0.075833 -0.324836 -0.115157  0.69834   0.36333   0.570732\n",
      "  0.126125 -0.03019  -0.209253 -0.29415   0.362377  0.336851]\n"
     ]
    }
   ],
   "source": [
    "print(model.vector_size)\n",
    "print(model['地铁'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b132cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "地铁 vs 公交 相似度： 0.5874173\n"
     ]
    }
   ],
   "source": [
    "similarity = model.similarity('地铁', '公交')\n",
    "print('地铁 vs 公交 相似度：', similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36d2f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('下班', 0.7061899304389954), ('上夜班', 0.644236147403717), ('上下班', 0.6376184225082397), ('值完', 0.6258902549743652), ('照常上班', 0.6204943060874939)]\n",
      "[('妈妈', 0.7957949638366699), ('母亲', 0.6855213046073914), ('爷爷', 0.6502836346626282)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeRelated\\codeService\\anaconda3\\envs\\npl-learning\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:851: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.most_similar(positive=[\"上班\"], topn=5)\n",
    "print(similar_words)\n",
    "result = model.most_similar(positive=[\"爸爸\", \"女性\"], negative=[\"男性\"], topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631f3fd",
   "metadata": {},
   "source": [
    "# 第二节 训练自己的词向量"
   ]
  },
  {
   "cell_type": "code",
   "id": "a293443e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:44:14.315546Z",
     "start_time": "2026-01-06T06:44:14.312591Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "4bfe424c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:44:16.128666Z",
     "start_time": "2026-01-06T06:44:15.990577Z"
    }
   },
   "source": "df = pd.read_csv('../../Data/online_shopping_10_cats.csv', encoding='utf-8', sep=',').dropna()  # sep默认是逗号",
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "7a434f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:44:17.172684Z",
     "start_time": "2026-01-06T06:44:17.166812Z"
    }
   },
   "source": [
    "df.head"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       cat  label                                             review\n",
       "0      书籍      1  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...\n",
       "1      书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2      书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3      书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4      书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...\n",
       "...    ..    ...                                                ...\n",
       "62769  酒店      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n",
       "62770  酒店      0  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...\n",
       "62771  酒店      0                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！\n",
       "62772  酒店      0  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...\n",
       "62773  酒店      0  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...\n",
       "\n",
       "[62773 rows x 3 columns]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "31c64c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:44:29.290591Z",
     "start_time": "2026-01-06T06:44:18.954469Z"
    }
   },
   "source": [
    "# df['review']\n",
    "sentences = [[token for token in jieba.lcut(sentence) if token.strip() != ''] for sentence in df['review']]"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fd77fa67096d476a"
  },
  {
   "cell_type": "code",
   "id": "b59861e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:50:24.080553Z",
     "start_time": "2026-01-06T06:50:24.072880Z"
    }
   },
   "source": "sentences[0:3]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['做',\n",
       "  '父母',\n",
       "  '一定',\n",
       "  '要',\n",
       "  '有',\n",
       "  '刘墉',\n",
       "  '这样',\n",
       "  '的',\n",
       "  '心态',\n",
       "  '，',\n",
       "  '不断',\n",
       "  '地',\n",
       "  '学习',\n",
       "  '，',\n",
       "  '不断',\n",
       "  '地',\n",
       "  '进步',\n",
       "  '，',\n",
       "  '不断',\n",
       "  '地',\n",
       "  '给',\n",
       "  '自己',\n",
       "  '补充',\n",
       "  '新鲜血液',\n",
       "  '，',\n",
       "  '让',\n",
       "  '自己',\n",
       "  '保持',\n",
       "  '一颗',\n",
       "  '年轻',\n",
       "  '的',\n",
       "  '心',\n",
       "  '。',\n",
       "  '我',\n",
       "  '想',\n",
       "  '，',\n",
       "  '这',\n",
       "  '是',\n",
       "  '他',\n",
       "  '能',\n",
       "  '很',\n",
       "  '好',\n",
       "  '的',\n",
       "  '和',\n",
       "  '孩子',\n",
       "  '沟通',\n",
       "  '的',\n",
       "  '一个',\n",
       "  '重要',\n",
       "  '因素',\n",
       "  '。',\n",
       "  '读',\n",
       "  '刘墉',\n",
       "  '的',\n",
       "  '文章',\n",
       "  '，',\n",
       "  '总能',\n",
       "  '让',\n",
       "  '我',\n",
       "  '看到',\n",
       "  '一个',\n",
       "  '快乐',\n",
       "  '的',\n",
       "  '平易近人',\n",
       "  '的',\n",
       "  '父亲',\n",
       "  '，',\n",
       "  '他',\n",
       "  '始终',\n",
       "  '站',\n",
       "  '在',\n",
       "  '和',\n",
       "  '孩子',\n",
       "  '同样',\n",
       "  '的',\n",
       "  '高度',\n",
       "  '，',\n",
       "  '给',\n",
       "  '孩子',\n",
       "  '创造',\n",
       "  '着',\n",
       "  '一个',\n",
       "  '充满',\n",
       "  '爱',\n",
       "  '和',\n",
       "  '自由',\n",
       "  '的',\n",
       "  '生活',\n",
       "  '环境',\n",
       "  '。',\n",
       "  '很',\n",
       "  '喜欢',\n",
       "  '刘墉',\n",
       "  '在',\n",
       "  '字里行间',\n",
       "  '流露出',\n",
       "  '的',\n",
       "  '做',\n",
       "  '父母',\n",
       "  '的',\n",
       "  '那种',\n",
       "  '小',\n",
       "  '狡黠',\n",
       "  '，',\n",
       "  '让',\n",
       "  '人',\n",
       "  '总是',\n",
       "  '忍俊不禁',\n",
       "  '，',\n",
       "  '父母',\n",
       "  '和',\n",
       "  '子女',\n",
       "  '之间',\n",
       "  '有时候',\n",
       "  '也',\n",
       "  '是',\n",
       "  '一种',\n",
       "  '战斗',\n",
       "  '，',\n",
       "  '武力',\n",
       "  '争斗',\n",
       "  '过于',\n",
       "  '低级',\n",
       "  '了',\n",
       "  '，',\n",
       "  '智力',\n",
       "  '较量',\n",
       "  '才',\n",
       "  '更',\n",
       "  '有',\n",
       "  '趣味',\n",
       "  '。',\n",
       "  '所以',\n",
       "  '，',\n",
       "  '做',\n",
       "  '父母',\n",
       "  '的',\n",
       "  '得',\n",
       "  '加把劲',\n",
       "  '了',\n",
       "  '，',\n",
       "  '老',\n",
       "  '思想',\n",
       "  '老',\n",
       "  '观念',\n",
       "  '注定',\n",
       "  '会',\n",
       "  '一败涂地',\n",
       "  '，',\n",
       "  '生命不息',\n",
       "  '，',\n",
       "  '学习',\n",
       "  '不止',\n",
       "  '。',\n",
       "  '家庭教育',\n",
       "  '，',\n",
       "  '真的',\n",
       "  '是',\n",
       "  '乐在其中',\n",
       "  '。'],\n",
       " ['作者',\n",
       "  '真有',\n",
       "  '英国人',\n",
       "  '严谨',\n",
       "  '的',\n",
       "  '风格',\n",
       "  '，',\n",
       "  '提出',\n",
       "  '观点',\n",
       "  '、',\n",
       "  '进行',\n",
       "  '论述',\n",
       "  '论证',\n",
       "  '，',\n",
       "  '尽管',\n",
       "  '本人',\n",
       "  '对',\n",
       "  '物理学',\n",
       "  '了解',\n",
       "  '不深',\n",
       "  '，',\n",
       "  '但是',\n",
       "  '仍然',\n",
       "  '能',\n",
       "  '感受',\n",
       "  '到',\n",
       "  '真理',\n",
       "  '的',\n",
       "  '火花',\n",
       "  '。',\n",
       "  '整本书',\n",
       "  '的',\n",
       "  '结构',\n",
       "  '颇',\n",
       "  '有',\n",
       "  '特点',\n",
       "  '，',\n",
       "  '从',\n",
       "  '当时',\n",
       "  '（',\n",
       "  '本',\n",
       "  '书写',\n",
       "  '于',\n",
       "  '八十年代',\n",
       "  '）',\n",
       "  '流行',\n",
       "  '的',\n",
       "  '计算机',\n",
       "  '话题',\n",
       "  '引入',\n",
       "  '，',\n",
       "  '再用',\n",
       "  '数学',\n",
       "  '、',\n",
       "  '物理学',\n",
       "  '、',\n",
       "  '宇宙学',\n",
       "  '做',\n",
       "  '必要',\n",
       "  '的',\n",
       "  '铺垫',\n",
       "  '—',\n",
       "  '—',\n",
       "  '这些',\n",
       "  '内容',\n",
       "  '占据',\n",
       "  '了',\n",
       "  '大部分',\n",
       "  '篇幅',\n",
       "  '，',\n",
       "  '最后',\n",
       "  '回到',\n",
       "  '关键问题',\n",
       "  '：',\n",
       "  '电脑',\n",
       "  '能',\n",
       "  '不能',\n",
       "  '代替',\n",
       "  '人脑',\n",
       "  '。',\n",
       "  '和',\n",
       "  '现在',\n",
       "  '流行',\n",
       "  '的',\n",
       "  '观点',\n",
       "  '相反',\n",
       "  '，',\n",
       "  '作者',\n",
       "  '认为',\n",
       "  '人',\n",
       "  '的',\n",
       "  '某种',\n",
       "  '“',\n",
       "  '洞察',\n",
       "  '”',\n",
       "  '是',\n",
       "  '不能',\n",
       "  '被',\n",
       "  '算法',\n",
       "  '模拟',\n",
       "  '的',\n",
       "  '。',\n",
       "  '也许',\n",
       "  '作者',\n",
       "  '想',\n",
       "  '说',\n",
       "  '，',\n",
       "  '人',\n",
       "  '的',\n",
       "  '灵魂',\n",
       "  '是',\n",
       "  '无可取代',\n",
       "  '的',\n",
       "  '。'],\n",
       " ['作者',\n",
       "  '长篇大论',\n",
       "  '借用',\n",
       "  '详细',\n",
       "  '报告',\n",
       "  '数据处理',\n",
       "  '工作',\n",
       "  '和',\n",
       "  '计算结果',\n",
       "  '支持',\n",
       "  '其新',\n",
       "  '观点',\n",
       "  '。',\n",
       "  '为什么',\n",
       "  '荷兰',\n",
       "  '曾经',\n",
       "  '县有',\n",
       "  '欧洲',\n",
       "  '最高',\n",
       "  '的',\n",
       "  '生产率',\n",
       "  '？',\n",
       "  '为什么',\n",
       "  '在',\n",
       "  '文化',\n",
       "  '上',\n",
       "  '有着',\n",
       "  '深刻',\n",
       "  '纽带',\n",
       "  '关系',\n",
       "  '的',\n",
       "  '中国',\n",
       "  '和',\n",
       "  '日本',\n",
       "  '却',\n",
       "  '在',\n",
       "  '经济',\n",
       "  '发展',\n",
       "  '上',\n",
       "  '有着',\n",
       "  '极大',\n",
       "  '的',\n",
       "  '差异',\n",
       "  '？',\n",
       "  '为什么',\n",
       "  '英国',\n",
       "  '的',\n",
       "  '北美',\n",
       "  '殖民地',\n",
       "  '造就',\n",
       "  '了',\n",
       "  '经济',\n",
       "  '强大',\n",
       "  '的',\n",
       "  '美国',\n",
       "  '，',\n",
       "  '而',\n",
       "  '西班牙',\n",
       "  '的',\n",
       "  '北美',\n",
       "  '殖民',\n",
       "  '却',\n",
       "  '造就',\n",
       "  '了',\n",
       "  '范后',\n",
       "  '的',\n",
       "  '墨西哥',\n",
       "  '？',\n",
       "  '…',\n",
       "  '…',\n",
       "  '很',\n",
       "  '有',\n",
       "  '价值',\n",
       "  '，',\n",
       "  '但',\n",
       "  '不',\n",
       "  '包括',\n",
       "  '【',\n",
       "  '中国',\n",
       "  '近代史',\n",
       "  '专业',\n",
       "  '】',\n",
       "  '。']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:50:35.875882Z",
     "start_time": "2026-01-06T06:50:25.799961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Word2Vec(\n",
    "    sentences,  # 已分词的句子序列\n",
    "    vector_size=100,  # 词向量的维度\n",
    "    window=5,  # 上下文窗口大小\n",
    "    min_count=2,  # 最小词频（低于将被忽略）\n",
    "    sg=1,  # 1：Skip-Gram，0：CBOW\n",
    "    workers=4,  # 并行训练线程数\n",
    ")# 实例化模型的同时确实开始了词向量的训练。"
   ],
   "id": "3c0bbc5594e9077a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:50:38.644527Z",
     "start_time": "2026-01-06T06:50:38.639783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.wv['地铁']\n",
    "model.wv.vector_size"
   ],
   "id": "eb4fe504694d9a61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:50:41.434070Z",
     "start_time": "2026-01-06T06:50:40.003636Z"
    }
   },
   "cell_type": "code",
   "source": "model.wv.save_word2vec_format('./data/word2vec.txt')",
   "id": "e9bcaaa277841204",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:50:44.496150Z",
     "start_time": "2026-01-06T06:50:42.015822Z"
    }
   },
   "cell_type": "code",
   "source": "KeyedVectors.load_word2vec_format('./data/word2vec.txt')['地铁']",
   "id": "908cecf29aceaabd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22488853,  0.42092636, -0.17300309,  0.17577414,  0.28958657,\n",
       "       -0.5624829 ,  0.20848933,  0.43081263, -0.6154931 ,  0.06341657,\n",
       "       -0.26661837, -0.41219366,  0.59604734, -0.27236134,  0.55199015,\n",
       "        0.23198873,  0.6127713 , -0.66558105, -0.2246045 , -0.3613789 ,\n",
       "        0.68532574, -0.23928666,  0.36542597,  0.01410825, -0.30508533,\n",
       "        0.09304506,  0.5409768 , -0.01797713, -0.18766832, -0.16107774,\n",
       "       -0.08907314, -0.31648368, -0.14819802, -0.3167416 ,  0.6365136 ,\n",
       "       -0.0278817 ,  0.17788051,  0.21568221,  0.17012103, -0.40443513,\n",
       "       -0.23867543,  0.29978076, -0.2011098 ,  0.37098473,  0.7842728 ,\n",
       "       -0.16457075, -0.05510465,  0.35331112, -0.04366172,  0.34606618,\n",
       "       -0.4136292 ,  0.2780064 ,  0.07506328, -0.18518507,  0.65557855,\n",
       "       -0.20213437,  0.25697568,  0.41541022, -0.474141  ,  0.34733754,\n",
       "       -0.22313502,  0.3987913 ,  0.1992021 , -0.07571858, -0.09558831,\n",
       "       -0.04716373,  0.46716234,  0.70260066, -0.03138976,  0.32664034,\n",
       "       -0.08278557, -0.3895175 ,  0.50285244,  0.6978435 , -0.04716138,\n",
       "        0.28486183,  0.08758078, -0.11657414,  0.22983962, -0.44988   ,\n",
       "       -0.33440807, -0.06361452, -0.4577038 , -0.06699517,  0.1440993 ,\n",
       "        0.021942  ,  0.22619402,  0.16180566,  0.409944  ,  0.5430085 ,\n",
       "        0.3471508 ,  0.00737333,  0.547311  ,  0.04141318, -0.36651722,\n",
       "        0.5038004 , -0.05413375, -0.07424454,  0.38796753,  0.11563198],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 第三节 词向量应用",
   "id": "141816707af04b7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 区分key_to_index和index_to_key返回数据的类型\n",
    "```pthon\n",
    "# 训练一个简单的 Word2Vec 模型\n",
    "model = Word2Vec(sentences, vector_size=10, window=5, min_count=1, sg=0)\n",
    "\n",
    "# key_to_index: 单词到索引的映射\n",
    "print(\"Key to Index:\", model.wv.key_to_index)\n",
    "# 输出: Key to Index: {'apple': 0, 'banana': 1, 'cherry': 2, 'dog': 3, 'cat': 4}\n",
    "\n",
    "# index_to_key: 索引到单词的映射\n",
    "print(\"Index to Key:\", model.wv.index_to_key)\n",
    "# 输出: Index to Key: ['apple', 'banana', 'cherry', 'dog', 'cat']\n",
    "```"
   ],
   "id": "733f3ad4f4c2375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:13:54.010565Z",
     "start_time": "2026-01-06T03:13:54.006022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from gensim.models import KeyedVectors\n",
    "import torch\n",
    "import jieba"
   ],
   "id": "60df6f398bc046ed",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:13:57.079598Z",
     "start_time": "2026-01-06T03:13:54.762241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.准备好词向量矩阵\n",
    "wv = KeyedVectors.load_word2vec_format('./data/word2vec.txt')"
   ],
   "id": "ad0d58cf31a73331",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:13:58.562607Z",
     "start_time": "2026-01-06T03:13:58.555606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 处理OOV\n",
    "# 在原有的此表上加入新词\n",
    "# 一般讲特殊词汇加入到开头（习惯上）\n",
    "unk_token = '<unk>'\n",
    "index2word = [unk_token] + wv.index_to_key\n",
    "word2index = {word: index for index, word in enumerate(index2word)}"
   ],
   "id": "e2849a7054c6ce63",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:14:00.795945Z",
     "start_time": "2026-01-06T03:14:00.512550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2.准备词向量矩阵\n",
    "num_embeddings = len(index2word)  # 检索出词向量\n",
    "print(\"num_embeddings\", num_embeddings)\n",
    "embedding_dim = wv.vector_size\n",
    "print(\"embedding_dim\", embedding_dim)\n",
    "embedding_matrix = torch.randn(num_embeddings, embedding_dim)  # 创建 (num_embeddings, embedding_dim)形状的tensor张量\n",
    "# print(embedding_matrix)\n",
    "for index, word in enumerate(index2word):\n",
    "    if word in wv:\n",
    "        embedding_matrix[index] = torch.tensor(wv[word])"
   ],
   "id": "e0c06f0ee2750abd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_embeddings 34577\n",
      "embedding_dim 100\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T03:28:07.996854Z",
     "start_time": "2026-01-06T03:28:07.992855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3.创建Embedding\n",
    "embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "print(embedding)"
   ],
   "id": "317cbaa87ae487b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(34577, 100)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:20:44.535011Z",
     "start_time": "2026-01-06T06:20:44.525512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4.测试\n",
    "# 这里容易出现OOV问题\n",
    "text = \"给我擦皮鞋\"\n",
    "tokens = jieba.lcut(text)\n",
    "print(tokens)\n",
    "input_ids = [word2index.get(token,word2index[unk_token]) for token in tokens]\n",
    "input_tensor = torch.tensor(input_ids)\n",
    "print(input_tensor)\n",
    "embedding(input_tensor)\n"
   ],
   "id": "eb93d1c87d54c191",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['给', '我', '擦皮鞋']\n",
      "tensor([28,  8,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1968,  0.1588,  0.1895, -0.1914,  0.7607, -0.1859,  0.4304,  0.2327,\n",
       "         -0.0793, -0.0188,  0.3871, -0.6174,  0.4740, -0.0052, -0.1786, -0.1930,\n",
       "         -0.2753, -0.0126,  0.1849, -0.2702,  0.1057,  0.1456,  0.6507,  0.3690,\n",
       "         -0.1901,  0.0398,  0.1246, -0.1694, -0.0733, -0.6120,  0.5980,  0.0599,\n",
       "          0.2279, -0.4735, -0.4726,  0.3080, -0.1696,  0.2086, -0.1610, -0.2779,\n",
       "         -0.1692, -0.3756,  0.1074,  0.3943, -0.2522, -0.1471,  0.1519, -0.4709,\n",
       "          0.0083, -0.0592, -0.4171, -0.5792,  0.3001, -0.0475, -0.3524,  0.2259,\n",
       "         -0.0697,  0.1007, -0.2514, -0.0028,  0.0928, -0.3455,  0.2034, -0.8628,\n",
       "         -0.2193, -0.0650,  0.1839,  0.2649, -0.2523, -0.1014, -0.6896, -0.4340,\n",
       "          0.5302, -0.1026, -0.0930,  0.3763,  0.0123, -0.3609, -0.4472, -0.1509,\n",
       "          0.0358,  0.3734,  0.2250,  0.4212, -0.2468, -0.4958,  0.1944, -0.2363,\n",
       "          0.1973, -0.1005,  0.1292, -0.3063,  0.0929, -0.2669,  1.3386,  0.1616,\n",
       "          0.1939,  0.2351, -0.6874, -0.3350],\n",
       "        [-0.0073, -0.1823, -0.0133, -0.2894,  0.1285, -0.3685,  0.3545,  0.2738,\n",
       "         -0.0064, -0.0066, -0.1939, -0.1843,  0.0252, -0.6898, -0.1822, -0.1813,\n",
       "         -0.0183, -0.1908,  0.0028, -0.4685,  0.3743,  0.0071,  0.1843, -0.2576,\n",
       "         -0.2371,  0.1167,  0.1746,  0.1684,  0.1341, -0.0908,  0.5086,  0.1400,\n",
       "          0.0478, -0.3879, -0.1260,  0.0706, -0.0109, -0.1633, -0.2364, -0.2602,\n",
       "          0.2049, -0.0477,  0.3515,  0.2970,  0.3050, -0.0800,  0.1717, -0.2026,\n",
       "          0.0100,  0.0094, -0.1385, -0.0891,  0.1403,  0.0827, -0.2521,  0.4488,\n",
       "          0.2053, -0.2129, -0.3644,  0.4051,  0.4426, -0.1215, -0.2046, -0.2351,\n",
       "         -0.2152,  0.4232,  0.1935,  0.6790, -0.0907,  0.1242, -0.2683, -0.1722,\n",
       "          0.3132, -0.1213, -0.1170,  0.0846,  0.2228,  0.0658, -0.0728,  0.0403,\n",
       "         -0.2790,  0.4031, -0.1653,  0.4897,  0.0806, -0.4449,  0.1078,  0.4669,\n",
       "          0.2329,  0.0521, -0.0401, -0.0310, -0.7133,  0.1332,  0.5712, -0.2183,\n",
       "          0.0643,  0.0066, -0.5096, -0.0922],\n",
       "        [ 1.1415,  0.1040,  0.4225,  1.1004,  0.6222, -0.0968,  0.5049,  1.4791,\n",
       "         -0.7320, -0.4020,  1.7154, -0.3599, -0.1956,  0.3199, -0.8048, -1.5286,\n",
       "          0.0561,  0.8807, -0.9508, -1.0315, -1.1173,  0.5962, -0.2965, -0.2045,\n",
       "          0.7191,  0.1751, -0.9974,  0.0970,  1.9032,  0.5236,  0.5680, -1.9370,\n",
       "          0.7405,  1.0199,  1.6345, -0.5557, -0.5903,  1.0835, -0.2199,  0.6336,\n",
       "         -0.4092, -2.4828,  1.0895, -0.5761,  1.1618,  0.6252,  0.4556, -0.2159,\n",
       "         -0.2633, -0.3710, -0.3609, -0.8266, -0.0611,  0.2428, -0.1041, -1.4483,\n",
       "         -1.0363, -1.9665, -1.1594,  0.1899, -0.0295, -0.2807, -0.2486, -1.5243,\n",
       "          1.5866, -0.0349, -1.0528,  1.5534, -0.9207, -0.1491, -0.3996, -1.9878,\n",
       "          0.4171, -1.1660,  0.6971,  0.3376,  0.9747,  2.3408, -0.1207, -0.3665,\n",
       "         -1.5356,  2.0887, -0.6399, -0.2255,  0.4669, -0.3462,  0.8470, -0.1981,\n",
       "         -1.2773, -0.0394, -0.5818, -0.4707,  1.6558, -1.2296,  0.3283, -0.1019,\n",
       "          0.9650, -0.0592,  0.2384,  0.6436]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "438d2f931d3c61fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
